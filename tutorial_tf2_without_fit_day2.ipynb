{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tutorial_tf2_without_fit_day2.ipynb","provenance":[{"file_id":"1zRMIxxWA5jH5iavYnH8WEVqrRSoXNegN","timestamp":1596242104070},{"file_id":"1-JPG2XB4iTc64fH8KHweKOIIeGITrp4m","timestamp":1596227393702}],"collapsed_sections":[],"authorship_tag":"ABX9TyN3XiDKlnAq3NpIlEdC5WSM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"XirG9UCfsBDf","colab_type":"text"},"source":["이 노트북은 김성훈 교수님의 모두를 위한 딥러닝 강좌 스크립트들을 참고, 재구성하여 만들어졌습니다.\n","\n","\n","(https://github.com/hunkim/DeepLearningZeroToAll/tree/master/tf2)"]},{"cell_type":"markdown","metadata":{"id":"fSaHRmp7R9Rz","colab_type":"text"},"source":["필요한 모듈들을 import합니다."]},{"cell_type":"code","metadata":{"id":"REP59ZCGR6IJ","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","# 텐서플로우 패키지\n","import tensorflow.keras.backend as K\n","# Low-Level API 패키지\n","import random\n","# 재현성을 위해 난수 Seed를 고정하기 위해 불러오는 패키지입니다.\n","from tensorflow.keras.datasets.mnist import load_data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oDWZ33PrTnyK","colab_type":"text"},"source":["하이퍼 패러미터와 난수 Seed를 설정합니다."]},{"cell_type":"code","metadata":{"id":"SuU-__3LTmcV","colab_type":"code","colab":{}},"source":["random.seed(777)\n","# 재현성을 위해 난수를 고정합니다.\n","\n","# Hyperparameters\n","# 하이퍼 패러미터란 학습으로 인해 자동으로 최적화되는 값이 아닌,\n","# 사람이 Huristic하게 최적의 값을 찾아나갈 수 밖에 없는 Parameter들입니다.\n","learning_rate = 0.001\n","# 한번에 얼만큼 업데이트 할 것인가에 대한 Hyperparameter입니다.\n","training_epochs = 15\n","# 에폭은 전체 데이터셋의 크기 만큼의 한 Loop를 일컫는 단위입니다. 총 몇 에폭 돌지 설정합니다.\n","batch_size = 100\n","# 한번에 Feed하는 이미지의 갯수를 결정합니다.\n","# 초심자 단계에서 당장 신경쓸 필요는 없지만 배치사이즈는 학습속도 뿐만 아니라 최종적인 성능에도 상당한 영향을 미친다고 알려져 있습니다.\n","drop_rate = 0.3\n","# Dropout을 할 때 얼만큼 데이터를 탈락시킬 지 결정하는 Parameter입니다.\n","# (1 - drop_rate)만큼 학습시에 데이터를 보존합니다.\n","# 최신버전 텐서플로우는 Dropout layer의 인자로 keep_prob 대신 rate를 전달하도록 권장하고 있는데(Keyword 인자로 전달 시 여전히 keep_prob도 사용가능하긴 함)\n","# 아마 Dropout에 전달하는 Non-Keyword 인자로서 이쪽이 더 직관적이라고 생각한 듯 합니다."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5KPTp1g5U305","colab_type":"text"},"source":["MNIST 데이터셋은 텐서플로우에서 자체적으로 제공하므로 텐서플로우 API를 이용해 데이터를 불러온 뒤 데이터 로더를 만들어 줍니다.\n","\n","Input을 1자로 펴주고, Label을 One-Hot 인코딩으로 전환해줍니다."]},{"cell_type":"code","metadata":{"id":"CBi6XRz9U0Q6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1596266354819,"user_tz":-540,"elapsed":9953,"user":{"displayName":"정현진","photoUrl":"","userId":"02319906487058652558"}},"outputId":"0acc7659-e0c3-4791-b5b2-e5d842c0f1f8"},"source":["(x_train, y_train), (x_test, y_test) = load_data()\n","# 텐서플로우에서 지원하는 API를 사용합니다.\n","# x_train, y_train 쌍은 학습 데이터셋의 Input, Label 쌍이고\n","# x_test, y_test 쌍은 평가 데이터셋의 Input, Label 쌍입니다.\n","\n","x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n","x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n","# Fully Connected Layer에 Feed하기 위해 Input(이미지)을 1자로 펴줍니다.\n","\n","y_train = tf.keras.utils.to_categorical(y_train, 10)\n","y_test = tf.keras.utils.to_categorical(y_test, 10)\n","# Label을 One-Hot 인코딩으로 전환해줍니다.\n","\n","data_train = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n","# DataLoader를 설정합니다."],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hg7YnPS9V17W","colab_type":"text"},"source":["모델을 구성합니다. 딥러닝 소스코드의 심장에 해당하는 부분입니다.\n","\n","\n","단순 일방향 Feeding 구조를 가진 모델을 구현할 때는 텐서플로우의 Sequential API를 사용하면 매우 편리합니다."]},{"cell_type":"code","metadata":{"id":"Up-LDpYFJ8AF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":485},"executionInfo":{"status":"ok","timestamp":1596266354821,"user_tz":-540,"elapsed":9946,"user":{"displayName":"정현진","photoUrl":"","userId":"02319906487058652558"}},"outputId":"1101e457-b2c7-436d-a8d3-d95430284294"},"source":["model = tf.keras.Sequential()\n","# tf.keras.Sequential API를 사용해 레이어들을 추가할 빈 신경망을 정의합니다.\n","\n","# 텐서플로우 2.X에서는 Layer를 정의함과 동시에 Sequential.add를 통해 바로 추가할 수 있습니다.\n","model.add(tf.keras.layers.Dense(input_dim=784, units=512, kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.05), use_bias=True, activation='relu'))\n","# 입력이 784 채널, 출력이 512 채널이고, Bias가 있으며, 활성화함수로 relu를 사용하는 Layer를 정규분포에서 초기화합니다.\n","# Bias들은 별도로 지정하지 않으면 0으로 초기화됩니다.\n","\n","model.add(tf.keras.layers.Dropout(drop_rate))\n","# Regularization을 위해 Dropout을 정의, 추가합니다.\n","\n","# 위와 같은 방식으로 나머지 부분의 신경망을 정의, 추가합니다.\n","model.add(tf.keras.layers.Dense(units=512, kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.05), use_bias=True, activation='relu'))\n","model.add(tf.keras.layers.Dropout(drop_rate))\n","model.add(tf.keras.layers.Dense(units=512, kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.05), use_bias=True, activation='relu'))\n","model.add(tf.keras.layers.Dropout(drop_rate))\n","model.add(tf.keras.layers.Dense(units=512, kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.05), use_bias=True, activation='relu'))\n","model.add(tf.keras.layers.Dropout(drop_rate))\n","model.add(tf.keras.layers.Dense(units=10, kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.05), use_bias=True, activation=None))\n","# 마지막 Layer의 활성화함수로는 SoftMax를 사용합니다.\n","\n","criterion = tf.keras.losses.categorical_crossentropy\n","# Loss Function을 정의합니다. \n","# Criterion = 척도 (Objective Function으로 직접 사용할 수 있는 척도)\n","# Metric = 척도 (Objective Function으로 직접 사용할 수 있을 수도 있고 없을 수도 있음)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n","# 최적화엔 Adam Optimizer를 사용합니다.\n","# model.parameters()로 Model에 등록된 학습가능한 모든 Parameter들을 불러오고\n","# learning_rate = learning_rate로 Hyperparameter인 Learning Rate를 입력해줍니다.\n","\n","model.summary()\n","# 정의한 모델을 한 번 출력해봅니다."],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense (Dense)                (None, 512)               401920    \n","_________________________________________________________________\n","dropout (Dropout)            (None, 512)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               262656    \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 512)               262656    \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 512)               262656    \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 10)                5130      \n","=================================================================\n","Total params: 1,195,018\n","Trainable params: 1,195,018\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"frvQEAXZlnS0","colab_type":"text"},"source":["텐서플로우는 단일 GPU이고 텐서플로우 GPU버전이 설치되어 있을 경우, 별도의 코드 추가 없이도 자동으로 GPU 가속이 적용됩니다."]},{"cell_type":"code","metadata":{"id":"KNt0ofQxlmAf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":503},"executionInfo":{"status":"ok","timestamp":1596266355091,"user_tz":-540,"elapsed":10204,"user":{"displayName":"정현진","photoUrl":"","userId":"02319906487058652558"}},"outputId":"e93a2be9-d233-47e9-d274-68ace46caeae"},"source":["from tensorflow.python.client import device_lib\n","device_lib.list_local_devices()\n","# GPU가 사용가능한지만 확인해줍니다."],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[name: \"/device:CPU:0\"\n"," device_type: \"CPU\"\n"," memory_limit: 268435456\n"," locality {\n"," }\n"," incarnation: 8937821572675027978, name: \"/device:XLA_CPU:0\"\n"," device_type: \"XLA_CPU\"\n"," memory_limit: 17179869184\n"," locality {\n"," }\n"," incarnation: 2982824834292927545\n"," physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n"," device_type: \"XLA_GPU\"\n"," memory_limit: 17179869184\n"," locality {\n"," }\n"," incarnation: 11359926252491882269\n"," physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n"," device_type: \"GPU\"\n"," memory_limit: 11150726272\n"," locality {\n","   bus_id: 1\n","   links {\n","   }\n"," }\n"," incarnation: 11788245293122063356\n"," physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"uQQ7BesUf50X","colab_type":"text"},"source":["텐서플로우 2.X에서는 일반적으로 직접 트레이닝 루프를 코딩할 필요가 없지만, 복잡한 Metric을 매 루프마다 확인하고 싶거나, 매 루프마다 특별한 처리가 필요할 때(주로 시계열 모델에서) 직접 트레이닝 루프를 코딩해야 할 필요가 있습니다. \n","\n","\n","텐서플로우 2.X의 트레이닝 루프 파이프라인은 파이토치와 매우 흡사합니다."]},{"cell_type":"code","metadata":{"id":"8udHl__vf8al","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":305},"executionInfo":{"status":"ok","timestamp":1596266484365,"user_tz":-540,"elapsed":139461,"user":{"displayName":"정현진","photoUrl":"","userId":"02319906487058652558"}},"outputId":"7c574ef4-0638-4d96-85de-9beb1bea001e"},"source":["for epoch in range(training_epochs):\n","  avg_cost = 0\n","  total_batch = len(x_train) // batch_size\n","  # '전체 데이터셋 길이'를 '한번에 Feed하는 배치사이즈'로 나누면\n","  # 한 에폭을 돌기위해 반복해야 할 루프횟수(total_batch)가 됩니다.\n","\n","  for i, (batch_xs, batch_ys) in enumerate(data_train): \n","    with tf.GradientTape() as tape:\n","      hypothesis = model(batch_xs, training=True)\n","      # hypothesis는 말 그대로 가설입니다. 내 모델을 통해 예측한 예측값(가설)이라고 생각하면 됩니다.\n","      # Softmax를 거치기 전 Logit도 가설이라고 할 수 있고 Softmax를 거친 확률 값도 가설이라고 할 수 있습니다.\n","      # training=True로 설정해서 Dropout을 적용하고\n","      # Batchnormalization 패러미터를 해당 배치에서 구해 이동평균법으로 갱신하는 등의 행동을 수행합니다.\n","      cost = K.mean(criterion(batch_ys, hypothesis, from_logits=True)) \n","      # == cost = K.mean(K.sum(-1 * batch_ys * (hypothesis - K.log(K.tile(K.expand_dims(K.sum(K.exp(hypothesis), axis=1), axis=1), [1, 10]))), axis=1))\n","      # Loss Function을 거친 뒤 나온 '실제 정답값과의 차이'를 구합니다.\n","\n","    grads = tape.gradient(cost, model.trainable_variables)\n","    # '실제 정답값과의 차이'를 모델에 속한 각 Variable들로 편미분한 값을 각 Variable에 전달하는 과정이 내부적으로 진행됩니다.\n","    \n","    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n","    # 각 Variable에 등록된 grad를 이용해 Weight 값을 Adam Optimization 방법으로 업데이트합니다.\n","    \n","    avg_cost += cost / total_batch\n","\n","  print(\"[Epoch: %7d] cost = %5.5f\"%(epoch + 1, avg_cost))\n","  # '실제 정답값과의 차이'가 얼마나 줄어들었는지 실시간으로 확인합니다.\n","\n","print('Learning Finished!')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[Epoch:       1] cost = 3.01749\n","[Epoch:       2] cost = 0.43125\n","[Epoch:       3] cost = 0.30616\n","[Epoch:       4] cost = 0.24884\n","[Epoch:       5] cost = 0.21975\n","[Epoch:       6] cost = 0.20080\n","[Epoch:       7] cost = 0.19027\n","[Epoch:       8] cost = 0.19341\n","[Epoch:       9] cost = 0.18529\n","[Epoch:      10] cost = 0.18217\n","[Epoch:      11] cost = 0.18019\n","[Epoch:      12] cost = 0.18011\n","[Epoch:      13] cost = 0.17526\n","[Epoch:      14] cost = 0.17526\n","[Epoch:      15] cost = 0.15999\n","Learning Finished!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CUmCrSldiElv","colab_type":"text"},"source":["학습이 완료된 모델을 이용해 정확도(Accuracy)를 구해봅니다."]},{"cell_type":"code","metadata":{"id":"88VZ1V78MTkx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1596266484371,"user_tz":-540,"elapsed":139450,"user":{"displayName":"정현진","photoUrl":"","userId":"02319906487058652558"}},"outputId":"098c9dad-d8fd-4f30-8d58-c24cf29db44b"},"source":["hypothesis = model(x_test, training=False)\n","# training=False로 모델을 Evaluation 모드로 바꿔줍니다.\n","# Batchnormalization 패러미터를 이동평균으로 바꿔주거나 Dropout을 없애주는 등의 역할을 수행합니다.\n","# 만약 이 함수로 인해 영향받지 않는 Layer를 만들고 싶다면 tf.keras.backend 패키지를 사용합니다.\n","\n","correct_prediction = tf.keras.backend.equal(tf.keras.backend.argmax(hypothesis, 1), tf.keras.backend.argmax(y_test, 1))\n","\n","accuracy = tf.keras.backend.mean(tf.cast(correct_prediction, tf.float32))\n","# Bool형식 데이터를 Float형식으로 바꾼 뒤 전체의 평균을 취하면 정확도를 구할 수 있습니다.\n","print('Accuracy:', accuracy.numpy())\n","# 정확도를 출력합니다."],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy: 0.9703\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LS7N5uFMkFgO","colab_type":"text"},"source":["모델이 잘 작동하는지 예시 하나를 직접 눈으로 확인합니다"]},{"cell_type":"code","metadata":{"id":"_lWb0HPBj_aD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1596266484373,"user_tz":-540,"elapsed":139442,"user":{"displayName":"정현진","photoUrl":"","userId":"02319906487058652558"}},"outputId":"ac4257bc-2f89-4d65-9338-5f1d322f4c9f"},"source":["import numpy as np\n","\n","random_index = random.randint(0, x_test.shape[0]-1)\n","# 랜덤한 인덱스를 하나 뽑습니다.\n","\n","hypothesis = model(tf.keras.backend.expand_dims(x_test[random_index], axis=0), training=False)\n","# training=False로 모델을 Evaluation 모드로 바꿔줍니다.\n","\n","print(\"Index: \", random_index)\n","print(\"Label: \", np.argmax(y_test[random_index]))\n","print(\"Prediction: \", np.argmax(hypothesis))\n","# 예측값과 정답을 비교해봅니다."],"execution_count":null,"outputs":[{"output_type":"stream","text":["Index:  3757\n","Label:  8\n","Prediction:  8\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kN_BA-D1RzaF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":283},"executionInfo":{"status":"ok","timestamp":1596266484612,"user_tz":-540,"elapsed":139672,"user":{"displayName":"정현진","photoUrl":"","userId":"02319906487058652558"}},"outputId":"02b3a0f2-607d-4408-fa36-864c44c34f05"},"source":["import matplotlib.pyplot as plt\n","\n","plt.imshow(np.squeeze(x_test[random_index].reshape(28, 28)))\n","# 예측에 사용했던 숫자의 이미지를 시각화 해봅니다."],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7fad204f5748>"]},"metadata":{"tags":[]},"execution_count":9},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOR0lEQVR4nO3de4xc5XnH8d/P61sxEDAO7spAjR1DSlthko0JgqZUtAmgUMM/CP8RQUK0qQoCUpKCUlWgIlVWCOTSUpAJFKcCEiRCoSmlOFYkKxfAa+KCzdUBO9jYuGAuhijGNk//2EOyMXveWc9dPN+PNJqZ88y759HYvz0z553Z1xEhAO9/k3rdAIDuIOxAEoQdSIKwA0kQdiCJyd3c2VRPi+ma0c1dAqn8Wm/p7djl8Wothd326ZK+KWlA0rcjYmnp8dM1Qyf6tFZ2CaDg4VhZW2v6ZbztAUk3SDpD0nGSltg+rtmfB6CzWnnPvkjShoh4LiLelvRdSYvb0xaAdmsl7HMkvTDm/uZq2++wPWx7xPbIbu1qYXcAWtHxs/ERsSwihiJiaIqmdXp3AGq0EvYtko4cc/+IahuAPtRK2FdLWmD7aNtTJZ0n6b72tAWg3ZqeeouIPbYvlvQ/Gp16uzUi1retMwBt1dI8e0TcL+n+NvUCoIP4uCyQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJtLSKK9DPBg75QG1t72uvd7GT/tBS2G1vlLRT0l5JeyJiqB1NAWi/dhzZ/zwiXm7DzwHQQbxnB5JoNewh6UHba2wPj/cA28O2R2yP7NauFncHoFmtvow/JSK22D5c0grbT0XEqrEPiIhlkpZJ0sGeGS3uD0CTWjqyR8SW6nq7pHskLWpHUwDar+mw255h+6B3b0v6pKR17WoMQHu18jJ+tqR7bL/7c+6IiAfa0hUgaWDBvGL9yStmFut/e9KK2tpPXptfHLvtrYOL9RnD7xTrezb+sljvhabDHhHPSTq+jb0A6CCm3oAkCDuQBGEHkiDsQBKEHUiCr7iio3ae9/Ha2tJ/uqk49sRpq4v1aZ5SrO+N+umxvznk+eLYAZePg7t+srtY/6s5HyvWe4EjO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwTw7yiYNFMu7/+KEYv3ur36ttra3wa5PWnNhsf7aC4cU6wdtqO99z/Tyvldf9I1i/fjbLy3W5+ln5R30AEd2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCeXYU7bigvO7HQ9fcUKz/Yo9ra5+/5IvFsR+895FyvViVPGVqbe3LT60pjr3vrdnF+rwr+m8evRGO7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBPPsyb3zp+Xvo//0mn8p1p/a/Xaxfta9l9fWFtz7UHFsIwPHfqhY33Zt/ffZT51e3vfGPS8U67edcGaxHj9fX6z3QsMju+1bbW+3vW7Mtpm2V9h+tro+tLNtAmjVRF7G3ybp9H22XSlpZUQskLSyug+gjzUMe0SskrRjn82LJS2vbi+XdHab+wLQZs2+Z58dEVur29sk1X6Q2PawpGFJmq4DmtwdgFa1fDY+IkJSFOrLImIoIoamaFqruwPQpGbD/pLtQUmqrre3ryUAndBs2O+TdH51+3xJ97anHQCd0vA9u+07JZ0qaZbtzZKukrRU0l22L5S0SdK5nWwSnRMD9d83l6RJKtc/veKSYv3YLz1aWxuYe1Rx7J5b6tdXl6Rr5t1RrC+cWv/f+/pXFxTH3nHjp4r1wefL8+iN/iZ+LzQMe0QsqSmd1uZeAHQQH5cFkiDsQBKEHUiCsANJEHYgCb7iipYsP+3mYv3bqz5RW/u3o/6jpX1/89UPF+uf/ed9v7/1W4PX/7Q49nCV6/04tdYIR3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJ59uRePaa1vx508rTy11A/fMR/19b+YftJxbGrL/losT55zdPF+uCvynPl2XBkB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkmGd/H5h8xJza2hNXDxbHPnXGtxr89PpljyfixP/6Ym3tmL9+pDh2kn5erJdn+LEvjuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATz7H3g7dM/Vqxv+nT5d/KKs66rrc2dfEBx7FnPLC7v+8G5xfoNn7+pWP/hGdfX1i5eOFwc+87aJ4p17J+GR3bbt9rebnvdmG1X295ie211ObOzbQJo1URext8mabylNb4eEQury/3tbQtAuzUMe0SskrSjC70A6KBWTtBdbPux6mX+oXUPsj1se8T2yG7tamF3AFrRbNhvlDRf0kJJWyXVniGKiGURMRQRQ1PU2h83BNC8psIeES9FxN6IeEfSzZIWtbctAO3WVNhtj/3e5DmS1tU9FkB/aDjPbvtOSadKmmV7s6SrJJ1qe6GkkLRR0hc62GPfG1gwr1h/9Vsu1h/4k/J3ykd2HVisf+quL9fWjv3GpuLYvS9uLdaPiBeL9ctfKf/TP3LVDbW1XbN+rzh2SrGK/dUw7BGxZJzNt3SgFwAdxMdlgSQIO5AEYQeSIOxAEoQdSIKvuFYGDptZrO/6Xv301zXzv1cce9ik8seEF91WP3UmSR+6eXOxPn/Tz2pre4ojG5t0QPkrsq//2a9b3AO6hSM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiSRZp598uDvF+tPXTG3WH/mD/+1tnbOhrOKY1+/9qhife4P6ufJpdbnyksGZh1WrG/40jHF+tOn1n+FVZJ+uedXtbWpr5bn6KNYxf7iyA4kQdiBJAg7kARhB5Ig7EAShB1IgrADSaSZZ3/xpkOK9R8cX7+0sCQt+sfLa2uzlj1UHDs9thXrjfijf1Ssv3zCwbW1Vz6ytzh2+enLivUTpz1QrC95frw1P3/rzc9+oLYWz64vjkV7cWQHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSTSzLOPDN1RrK/fXf69t+uQ+mWX5z8yrTh2sstz3Y1cN/idYn2S6nu7fefhxbEXPnRBsT7rP6cX6wffWf6MgfRKgzq6peGR3faRtn9k+wnb621fWm2faXuF7Wer60M73y6AZk3kZfweSZdHxHGSPi7pItvHSbpS0sqIWCBpZXUfQJ9qGPaI2BoRj1a3d0p6UtIcSYslLa8etlzS2Z1qEkDr9us9u+25kk6Q9LCk2RGxtSptkzS7ZsywpGFJmq7yumEAOmfCZ+NtHyjpbkmXRcQbY2sREar5+4ARsSwihiJiaIrKJ7IAdM6Ewm57ikaDfntEfL/a/JLtwao+KGl7Z1oE0A4ePSgXHmBbo+/Jd0TEZWO2XyvplYhYavtKSTMj4u9KP+tgz4wTfVob2t5/Oz53UrF+9Oee6VIn77V2VfnPNc94sX5qTZIGdtX/Gx52c/nPVOP95eFYqTdix7j/YSbynv1kSZ+R9LjttdW2r0haKuku2xdK2iTp3HY0C6AzGoY9In4s1X5qozeHaQD7jY/LAkkQdiAJwg4kQdiBJAg7kETDefZ26uU8O5BBaZ6dIzuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTRMOy2j7T9I9tP2F5v+9Jq+9W2t9heW13O7Hy7AJo1kfXZ90i6PCIetX2QpDW2V1S1r0fE1zrXHoB2mcj67Fslba1u77T9pKQ5nW4MQHvt13t223MlnSDp4WrTxbYfs32r7UNrxgzbHrE9slu7WmoWQPMmHHbbB0q6W9JlEfGGpBslzZe0UKNH/uvGGxcRyyJiKCKGpmhaG1oG0IwJhd32FI0G/faI+L4kRcRLEbE3It6RdLOkRZ1rE0CrJnI23pJukfRkRFw/ZvvgmIedI2ld+9sD0C4TORt/sqTPSHrc9tpq21ckLbG9UFJI2ijpCx3pEEBbTORs/I8ljbfe8/3tbwdAp/AJOiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKOiO7tzP4/SZvGbJol6eWuNbB/+rW3fu1LordmtbO3P4iID45X6GrY37NzeyQihnrWQEG/9tavfUn01qxu9cbLeCAJwg4k0euwL+vx/kv6tbd+7Uuit2Z1pbeevmcH0D29PrID6BLCDiTRk7DbPt3207Y32L6yFz3Usb3R9uPVMtQjPe7lVtvbba8bs22m7RW2n62ux11jr0e99cUy3oVlxnv63PV6+fOuv2e3PSDpGUl/KWmzpNWSlkTEE11tpIbtjZKGIqLnH8Cw/QlJb0r6TkT8cbXtq5J2RMTS6hfloRFxRZ/0drWkN3u9jHe1WtHg2GXGJZ0t6QL18Lkr9HWuuvC89eLIvkjShoh4LiLelvRdSYt70Effi4hVknbss3mxpOXV7eUa/c/SdTW99YWI2BoRj1a3d0p6d5nxnj53hb66ohdhnyPphTH3N6u/1nsPSQ/aXmN7uNfNjGN2RGytbm+TNLuXzYyj4TLe3bTPMuN989w1s/x5qzhB916nRMRHJJ0h6aLq5WpfitH3YP00dzqhZby7ZZxlxn+jl89ds8uft6oXYd8i6cgx94+otvWFiNhSXW+XdI/6bynql95dQbe63t7jfn6jn5bxHm+ZcfXBc9fL5c97EfbVkhbYPtr2VEnnSbqvB328h+0Z1YkT2Z4h6ZPqv6Wo75N0fnX7fEn39rCX39Evy3jXLTOuHj93PV/+PCK6fpF0pkbPyP9C0t/3ooeavuZJ+t/qsr7XvUm6U6Mv63Zr9NzGhZIOk7RS0rOSfihpZh/19u+SHpf0mEaDNdij3k7R6Ev0xyStrS5n9vq5K/TVleeNj8sCSXCCDkiCsANJEHYgCcIOJEHYgSQIO5AEYQeS+H/1qTFxg5HyXwAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"LGjZJlgaqpKz","colab_type":"text"},"source":["위 과정을 모두 완료하셨으면 오버피팅 현상을 경험해보기 위해 학습을 더 시키고 정확도를 확인해 봅시다."]}]}